{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import custom_funcs as cf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "import sklearn.cross_validation as cv\n",
    "\n",
    "from Bio import SeqIO\n",
    "from Bio.Align import MultipleSeqAlignment\n",
    "from itertools import combinations\n",
    "from random import sample\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.ensemble import RandomForestRegressor, ExtraTreesRegressor, AdaBoostRegressor, GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem Set on Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "locked": false,
     "solution": false
    }
   },
   "source": [
    "## Problem 1\n",
    "\n",
    "Identify an academic literature reference that descirbes the PhenoSense assay. Paste the URL to the PubMed article below, and write a 1-2 sentence summary on what is measured in the assay, and how it relates to drug resistance.\n",
    "\n",
    "Compare and contrast it with the plaque reduction assay as mentioned in the literature - what would be one advantage of the plaque reduction assay that is lacking in PhenoSense, and vice versa?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "phenosense",
     "locked": false,
     "points": 3,
     "solution": true
    }
   },
   "source": [
    "**Answer**\n",
    "\n",
    "Double-click on this cell to type in your answer. Use Markdown formatting if you'd like.\n",
    "\n",
    "A new paragraph is delineated by having a line in between them. You can **bold** or *italicize* text. \n",
    "\n",
    "- Bulleted\n",
    "- Lists\n",
    "    - are done this way.\n",
    "    - 4 spaces for indents.\n",
    "    \n",
    "1. Numbered\n",
    "1. Lists \n",
    "    1. are done this way.\n",
    "    1. 4 spaces for indents.\n",
    "    1. The numbering is automatically parsed!\n",
    "    \n",
    "Leave the **answer** at the top so Claire can know where your answer is!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 2\n",
    "\n",
    "1. Write code below to calculate the correlation between two drugs' resistance profiles. Identify the protease drugs for which the two drugs' resistance values are correlated. \n",
    "1. Speculate as to why they would be correlated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "load_data",
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "# This cell loads the data and cleans it for you, and log10 transforms the drug resistance values.\n",
    "# Remember to run this cell if you want to have the data loaded into memory.\n",
    "DATA_HANDLE = 'drug_data/hiv-protease-data.csv'  # specify the relative path to the protease drug resistance data\n",
    "N_DATA = 8  # specify the number of columns in the CSV file that are drug resistance measurements.\n",
    "CONSENSUS = 'sequences/hiv-protease-consensus.fasta'  # specify the relative path to the HIV protease consensus sequence\n",
    "data, drug_cols, feat_cols = cf.read_data(DATA_HANDLE, N_DATA)\n",
    "consensus_map = cf.read_consensus(CONSENSUS)\n",
    "data = cf.clean_data(data, feat_cols, consensus_map)\n",
    "for name in drug_cols:\n",
    "    data[name] = data[name].apply(np.log10)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "nbgrader": {
     "grade": false,
     "grade_id": "drug_correlation_score",
     "locked": false,
     "solution": true
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Complete the function below to compute the correlation score.\n",
    "\n",
    "Use the scipy.stats.pearsonr(x, y) function to find the correlation score between two arrays of things. \n",
    "You do not need to type the whole name, as I have imported the pearsonr name for you, so you only have to do:\n",
    "\n",
    "    pearsonr(x, y)\n",
    "\n",
    "Procedure:\n",
    "\n",
    "1. Select two columns' names to compare.\n",
    "2. Make sure to drop NaN values. the pearsonr function cannot deal with NaN values. \n",
    "   (Refer to the Lecture notebook if you forgot how to do this.)\n",
    "3. Pass the data in to pearsonr().\n",
    "\n",
    "\"\"\"\n",
    "def corr_score(drug1, drug2):\n",
    "    ### BEGIN SOLUTION\n",
    "    # Get the subset of data, while dropping columns that have NaN in them.\n",
    "    \n",
    "    # Return the pearsonr score.\n",
    "    return pearsonr(____________, ____________)\n",
    "    ### END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "drug_correlation_tests",
     "locked": true,
     "points": 1,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "assert corr_score('IDV', 'FPV') == (0.79921991532901282, 2.6346448659104859e-306)\n",
    "assert corr_score('ATV', 'FPV') == (0.82009597442033089, 2.5199367322520278e-231)\n",
    "assert corr_score('NFV', 'DRV') == (0.69148264851159791, 4.0640711263961111e-82)\n",
    "assert corr_score('LPV', 'SQV') == (0.76682619729899326, 4.2705737581002648e-234)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** Which two drugs are most correlated?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "drug_correlation_mechanism",
     "locked": false,
     "points": 3,
     "solution": true
    }
   },
   "source": [
    "**Question:** Why might they be correlated? (Hint: you can look online for what they look like.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Problem 3\n",
    "\n",
    "Fill in the code below to plot the relationship between number of estimators (X-axis) and the MSE value for each of the estimators. \n",
    "\n",
    "- Try 10, 30, 50, 80, 100, 300, 500 and 800 estimators. \n",
    "- Use the ShuffleSplit iterator with cross-validation.\n",
    "- Use mean of at least 5 cross-validated MSE scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def return_cleaned_data(drug_name, data):\n",
    "    # Select the subsets of columns of interest.\n",
    "    cols_of_interest = []\n",
    "    cols_of_interest.append(drug_name)\n",
    "    cols_of_interest.extend(feat_cols)\n",
    "    subset = data[cols_of_interest].dropna() \n",
    "    Y = subset[drug_name]  \n",
    "    X = subset[feat_cols]\n",
    "    \n",
    "    # Binarize the columns.\n",
    "    lb = LabelBinarizer()\n",
    "    lb.fit(list('CHIMSVAGLPTRFYWDNEQK'))\n",
    "\n",
    "    X_binarized = pd.DataFrame()\n",
    "\n",
    "    for col in X.columns:\n",
    "        binarized_cols = lb.transform(X[col])\n",
    "\n",
    "        for i, c in enumerate(lb.classes_):\n",
    "            X_binarized[col + '_' + c] = binarized_cols[:,i]\n",
    "    \n",
    "    return X_binarized, Y\n",
    "\n",
    "X_binarized, Y = return_cleaned_data('FPV', data)\n",
    "len(X_binarized), len(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "num_estimators = [_________]  # fill in the list of estimators to try here.\n",
    "models = {'Random Forest':RandomForestRegressor,\n",
    "          }  # fill in the other models here\n",
    "\n",
    "# Initialize a dictionary to hold the models' MSE values.\n",
    "mses = dict()\n",
    "for model_name, model in models.items():\n",
    "    mses[model_name] = dict()\n",
    "    for n in num_estimators:\n",
    "        mses[model_name][n] = 0\n",
    "\n",
    "# Iterate over the models, and number of estimators.\n",
    "for model_name, model in models.items():\n",
    "    for n_est in num_estimators:\n",
    "        print(model_name, n_est)\n",
    "        ### Begin Here\n",
    "        \n",
    "        # Set up the cross-validation iterator\n",
    "        \n",
    "        # Initialize the model\n",
    "        \n",
    "        # Collect the cross-validation scores. Remember that mse will be negative, and needs to\n",
    "        # be transformed to be positive.\n",
    "        \n",
    "        \n",
    "        \n",
    "        ### End Here\n",
    "        \n",
    "        \n",
    "        # Store the mean MSEs.\n",
    "        mses[model_name][n_est] = np.mean(-cv_scores)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# When you're done, run the following cell to make your plot.\n",
    "pd.DataFrame(mses).plot()\n",
    "plt.xlabel('Num Estimators')\n",
    "plt.ylabel('MSE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:** Given the data above, consider the following question from the viewpoint of a data scientist/data analyst. What factors do you need to consider when tweaking model parameters?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 4\n",
    "\n",
    "- Pick the best model from above, and re-train it on the dataset again. Refer to the Lecture notebook for a version of the code that may help here!\n",
    "- Now, use it to make predictions on the global HIV protease dataset.\n",
    "- Plot the global distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load in the data and binarize it.\n",
    "proteases = [s for s in SeqIO.parse('sequences/HIV1-protease.fasta', 'fasta') if len(s) == 99]\n",
    "alignment = MultipleSeqAlignment(proteases)\n",
    "proteases_df = pd.DataFrame(np.array([list(rec) for rec in alignment], str))\n",
    "proteases_df.index = [s.id for s in proteases]\n",
    "proteases_df.columns = [i for i in range(1, 100)]\n",
    "X_global = cf.binarize_seqfeature(proteases_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Train your model here, with optimized parameters for best MSE minimization.\n",
    "### BEGIN\n",
    "model = ________________(__________)  # put your best model here, with optimized parameters.\n",
    "model.fit(______________)\n",
    "preds = model.predict(______________)\n",
    "plt.hist(preds)\n",
    "### END"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question:**\n",
    "\n",
    "How would you evaluate whether the predictions are correct?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**Answer**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**Question:** In the procedure we have used here, we have done the following:\n",
    "\n",
    "1. Randomly subdivide the whole training data into a subset training and testing set.\n",
    "1. Used cross-validation over multiple random splits to select the best model.\n",
    "1. Re-train best model on the entire dataset.\n",
    "1. Use the trained model to make predictions about new data.\n",
    "\n",
    "Think through the procedure for a moment. What assumptions about the training data have we made in using this procedure to train the ML models?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
