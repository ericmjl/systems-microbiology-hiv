{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Read in the data\n",
    "import pandas as pd\n",
    "import custom_funcs as cf\n",
    "import numpy as np\n",
    "\n",
    "from bokeh.charts import Histogram, Scatter\n",
    "from bokeh import plotting as bplt\n",
    "from bokeh.plotting import ColumnDataSource\n",
    "from ipywidgets import widgets, interact, Dropdown\n",
    "from IPython.display import display\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn import cross_validation as cv\n",
    "from sklearn.ensemble import RandomForestRegressor, ExtraTreesRegressor, GradientBoostingRegressor, AdaBoostRegressor\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from Bio import SeqIO\n",
    "from Bio.Align import MultipleSeqAlignment\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "bplt.output_notebook()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Machine Learning in Python using `scikit-learn`\n",
    "\n",
    "## Learning Outcomes\n",
    "\n",
    "From the lectures, you should be able to:\n",
    "\n",
    "1. Describe the role of HIV protease and reverse transcriptase.\n",
    "1. Describe the mechanism, at the biochemical level, how protease and reverse transcriptase inhibitors function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "By the end of this portion of the class, you should be equipped to:\n",
    "\n",
    "1. Transform protein sequence data into an input suitable for machine learning purposes.\n",
    "1. Describe the importance of splitting the data into training, testing, and validation sets.\n",
    "1. Use the scikit-learn API to split your data into training and testing sets.\n",
    "1. Use the scikit-learn API to train a machine learning model to learn how to map from genotype to phenotype.\n",
    "1. Describe the difference between a model parameter and hyperparameters.\n",
    "1. Be ready to tackle the pset!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Question\n",
    "\n",
    "If I gave you the protein sequence of an HIV protease, could you tell the degree to which the protease is resistant to a particular drug? What kind of data would you need?\n",
    "\n",
    "- From a clinical perspective: If a new patient came in, and you had to prescribe a drug combination for their infection, how would you tell which drugs to give, given the genomic data?\n",
    "\n",
    "- From an epidemiological perspective: How would you tell whether drug resistance is shaping the evolution of the virus? What kind of data would you need to answer this question?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Machine Learning Tasks\n",
    "\n",
    "1. Supervised\n",
    "1. Unsupervised\n",
    "\n",
    "What are some examples of each?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Supervised Machine Learning\n",
    "\n",
    "1. **Gold standard:** Model directly learns relationship between features and outcomes.\n",
    "1. **Expensive:** Requires structured data collected in a representative fashion.\n",
    "1. **Worthwhile:** As long as your measurement accurately measures what you're inferring, supervised ML will work well.\n",
    "1. **Features are everything:**\n",
    "    1. Feature engineering: transforming numerical features correctly to feed into model.\n",
    "    1. Feature selection: figuring out what are the most important predictor variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "If you can set up your machine learning problem as \"learning the relationship between features and outcomes\", then you are good to go for doing machine learning.\n",
    "\n",
    "| Feature 1 | Feature 2 | Feature 3 | Outcome 1 | Outcome 2 |\n",
    "|-----------|-----------|-----------|-----------|-----------|\n",
    "| Obs 1     | Obs 2     | Obs 3     | Val 1     | Val 2     |\n",
    "|   ...     |    ...    |    ...    |    ...    |    ...    |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Outcomes\n",
    "\n",
    "Outcomes can be grouped under two types: \n",
    "\n",
    "- **Classes:** Discrete labels (i.e. dog, cat, human, pig). Problems involving classes are **classification problems**.\n",
    "- **Numbers:** A continuuous measurement. Problems involving numbers are **regression problems**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Let's get started\n",
    "\n",
    "We will use one drug and one protein as an example to figure out how to write the code that transforms the data from sequence to insight."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Load the Data\n",
    "\n",
    "The data are derived from the [Stanford HIV Database][1]. The data are collected by measuring the fold drug resistance in a standardized drug resistance assay, also known as the [PhenoSense Assay][2]. As such, this is a high quality, matched genotype-phenotype dataset.\n",
    "\n",
    "I have written some custom functions in the `custom_funcs.py` module to aid with data loading. Run the cell below.\n",
    "\n",
    "[1]: http://hivdb.stanford.edu\n",
    "[2]: http://www.monogrambio.com/hiv-tests/phenotype-assays/phenosense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "DATA_HANDLE = 'drug_data/hiv-protease-data.csv'  # specify the relative path to the protease drug resistance data\n",
    "N_DATA = 8  # specify the number of columns in the CSV file that are drug resistance measurements.\n",
    "CONSENSUS = 'sequences/hiv-protease-consensus.fasta'  # specify the relative path to the HIV protease consensus sequence\n",
    "\n",
    "data, drug_cols, feat_cols = cf.read_data(DATA_HANDLE, N_DATA)\n",
    "\n",
    "consensus_map = cf.read_consensus(CONSENSUS)\n",
    "\n",
    "data = cf.clean_data(data, feat_cols, consensus_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Explore the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "data.head() # alternatively, data.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "**Explore**\n",
    "\n",
    "Before we go any further, I think it is valuable to explore the dataset further. Below is an interactive tool to explore the data.\n",
    "\n",
    "As you look through it, discuss the following question with each other:\n",
    "\n",
    "1. How would you describe the distribution of the data? What view of the data are you describing it from? (log10 or non-log10?) \n",
    "1. Are you surprised by negative values when the log10 transformation is performed?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "def histogram(drug, bins=50, log10='False'):\n",
    "    src = data[[drug]].dropna()\n",
    "    xlabel = 'Drug Resistance Values'\n",
    "    if log10 == \"True\":\n",
    "        src = src.apply(lambda x: np.log10(x))\n",
    "        xlabel = 'log10 (Drug Resistance Value)'\n",
    "    p = Histogram(data=src, \n",
    "                  title='Distribution of {0} Drug Resistance Values'.format(drug),\n",
    "                  xlabel=xlabel, \n",
    "                  ylabel='Count',\n",
    "                  bins=bins, \n",
    "                  width=900, \n",
    "                  height=300)\n",
    "    bplt.show(p)\n",
    "\n",
    "interact(histogram, drug=[i for i in drug_cols], bins=[10, 80, 10], log10=[\"False\", \"True\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's also take a look at the correlations between the drug resistance values. Think about the following question:\n",
    "\n",
    "1. Are there correlations between drug resistance values?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def scatter(drug1, drug2, log10=\"False\"):\n",
    "    p = bplt.figure(x_axis_label=drug1,\n",
    "                    y_axis_label=drug2,\n",
    "                    plot_height=300,\n",
    "                    plot_width=300)\n",
    "    src = data[[drug1, drug2]].dropna()\n",
    "    if log10 == \"True\":\n",
    "        src = src.apply(np.log10)\n",
    "    src = ColumnDataSource(src)\n",
    "    p.circle(source=src, x=drug1, y=drug2)\n",
    "    bplt.show(p)    \n",
    "\n",
    "interact(scatter, \n",
    "         drug1=[i for i in drug_cols][::-1], \n",
    "         drug2=[i for i in drug_cols],\n",
    "         log10=['True', 'False'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's work with only one drug: FPV. We will reduce the data such that we only have FPV drug resistance values with the sequence feature matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "cols_of_interest = []\n",
    "cols_of_interest.append('FPV')\n",
    "cols_of_interest.extend(feat_cols)\n",
    "fpv = data[cols_of_interest]\n",
    "fpv.head(10) # change to: fpv.dropna().head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "Notice how there are NaN values present. These will cause issues for us later on. \n",
    "\n",
    "- This most probably stems from experimental data not being present for that sequence.\n",
    "- Therefore, it should not be used for model training. \n",
    "- Filling/substituting it with 0 also does not help, as it was not actually measured to have 0 drug resistance.\n",
    "- We will have to drop rows that have `NaN` values.\n",
    "\n",
    "**Exercise**\n",
    "\n",
    "Let's try to write a function together that will give us a cleaned data set, which you can use later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "def one_drug_data(drug_name):\n",
    "    \n",
    "    # append and extend are two methods for lists.\n",
    "    # append adds a single item to the end of the list.\n",
    "    # extend iterates over the list passed into the function, and appends it to the end of the list.\n",
    "    \n",
    "    # What is the function call to remove rows with NaN values in it?\n",
    "    \n",
    "    return drug_data\n",
    "\n",
    "fpv = one_drug_data('FPV')\n",
    "fpv.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the scatterplots and histograms show, it may be wise to log10 transform the drug resistance value, so that we can work with a less skewed distribution.\n",
    "\n",
    "**Exercise**\n",
    "\n",
    "Fill in the function below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def log10_drug_data(drug_name):\n",
    "    # Comment out drug_name.\n",
    "    drug_data = one_drug_data(________)\n",
    "    drug_data[________] = drug_data[________].apply(np.log10)\n",
    "    \n",
    "    return drug_data\n",
    "\n",
    "fpv = log10_drug_data(\"FPV\")\n",
    "fpv.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Exercise\n",
    "\n",
    "Now that we have cleaned the data, let's split it into the feature and outcome columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "def split_xy(data, X_colnames, Y_colnames):\n",
    "    \"\"\"\n",
    "    The \"X\" matrix will be the feature columns.\n",
    "    The \"Y\" matrix (or column in this case) will be the outcome column(s).\n",
    "    \"\"\"\n",
    "    \n",
    "    return data[_________], data[___________]\n",
    "\n",
    "X, Y = split_xy(fpv, feat_cols, 'FPV')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convince yourself that they've been split correctly, by running the following two cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Problem\n",
    "\n",
    "`scikit-learn` ML models can't take in strings. How can we transform this into numbers?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Solution\n",
    "\n",
    "Binarize each column into 1s and 0s representing whether an amino acid is present in that position. Run the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "lb = LabelBinarizer()\n",
    "lb.fit(list('CHIMSVAGLPTRFYWDNEQK'))\n",
    "\n",
    "X_binarized = pd.DataFrame()\n",
    "\n",
    "for col in X.columns:\n",
    "    binarized_cols = lb.transform(X[col])\n",
    "    \n",
    "    for i, c in enumerate(lb.classes_):\n",
    "        X_binarized[str(col) + '_' + str(c)] = binarized_cols[:,i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convince yourself, now, that X_binarized is indeed binarized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_binarized.head().iloc[:,0:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Train a model!\n",
    "\n",
    "Let's train the Random Forest Regressor model.\n",
    "\n",
    "**Question:**\n",
    "\n",
    "Briefly, at a high level, how does the Random Forest algorithm work?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "## Ensemble Learners\n",
    "\n",
    "Uses an **ensemble of** (i.e. many) \"weak\" learners to learn the association between the features and the outcome.\n",
    "\n",
    "Random Forest is based on an ensemble of decision trees. What might be a \"strong\" decision tree, and what might be a \"weak\" decision tree?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train/Test Split\n",
    "\n",
    "Before we train the model, we need to first split the data into two chunks, the **training set** and the **testing set**. Why would this be important? Why couldn't we simply train and test on the whole dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Split the data into two sets, the training and testing set.\n",
    "X_train, X_test, Y_train, Y_test = cv.train_test_split(X_binarized, Y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# NOTE: This is the code you may want to use for your pset! \n",
    "# The code associated with cells that are interactive may not be best suited to your use case.\n",
    "# Initialize the model\n",
    "rfr = RandomForestRegressor()\n",
    "# Call on the \"model.fit()\" function.\n",
    "rfr.fit(X_train, Y_train)\n",
    "# Make a prediction on the test set.\n",
    "Y_preds = rfr.predict(X_test)\n",
    "# Evaluate the model by calculating the mean-squared error.\n",
    "mse(Y_test, Y_preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question**\n",
    "\n",
    "What is the mean-squared error metric actually measuring? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Model Evaluation: Cross-Validation\n",
    "\n",
    "During the model training and evaluation phase, we want to know which models will generalize best. Therefore, it is important to use cross-validation on the data.\n",
    "\n",
    "In cross-validation procedure we are going to use here is called fractional shuffled cross validation, the data are:\n",
    "\n",
    "1. Shuffle the rows of the data.\n",
    "1. Split data randomly into a training set and test set, with the training set being some fraction of the entire data set.\n",
    "1. Train on training set, measure accuracy on test set. \n",
    "1. Repeat until procedure has been done `X` times.\n",
    "\n",
    "There's nothing special about the name, I made it up. :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise**\n",
    "\n",
    "Play around with the interactive widgets below, and let us know which model you think should be considered the best. Note: some models take a long time to run. Also, the more the number of iterations, the longer it should take."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import math\n",
    "def assess_model(model, n_iters):\n",
    "    model = eval(model)\n",
    "    n_iters = int(n_iters)\n",
    "    cv_iterator = cv.ShuffleSplit(len(X_binarized), n_iter=n_iters, test_size=0.3)\n",
    "    cv_scores = cv.cross_val_score(model(), \n",
    "                                   X_binarized, \n",
    "                                   Y, \n",
    "                                   cv=cv_iterator, \n",
    "                                   scoring='mean_squared_error')\n",
    "    # note: we return negative of mean squared error because of a known issue in scikit-learn\n",
    "    # where the MSE is returned as a negative value. Therefore, to get back the positive value,\n",
    "    # we have to take the negative of the array of values.\n",
    "    return -cv_scores\n",
    "\n",
    "interact(assess_model, \n",
    "         model=['RandomForestRegressor', 'AdaBoostRegressor', 'ExtraTreesRegressor', 'GradientBoostingRegressor'],\n",
    "         n_iters=Dropdown(description='n_iters', options=['5', '6', '7', '8', '9', '10', '11', '12']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise**\n",
    "\n",
    "Modify the `assess_model` function such that it returns the **mean** and the **standard deviation** of the CV scores.\n",
    "\n",
    "The following block of code should help illustrate for you acceptable coding patterns:\n",
    "\n",
    "    def function(param1, param2):\n",
    "        # do stuff with param1 and param2\n",
    "        result1 = #stuff done with param1\n",
    "        result2 = #stuff done with param2\n",
    "        return result1, result2\n",
    "        \n",
    "Also, the `numpy` function has been imported in the `np` namespace, so you can access the following functions:\n",
    "\n",
    "- `np.mean(array_of_values)` will give you the mean.\n",
    "- `np.std(array_of_values)` will give you the standard deviation.\n",
    "\n",
    "When you're done, don't forget to re-run the cell, so that the function can be updated, before playing with the drop-down menu values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question**\n",
    "\n",
    "Which model performs the best?\n",
    "\n",
    "Once we know which model performs the best, we can go on to tweak it further.\n",
    "\n",
    "Note: We haven't tweaked the parameters in the model yet! Thus far, we have yet to optimize model performance. Take a look at each of the following model's API documentation pages to see what parameters can be tweaked:\n",
    "\n",
    "- [Random Forest Regressor][1]\n",
    "- [Extremely Randomized Trees Regressor][2]\n",
    "- [AdaBoost Regressor][3]\n",
    "- [Gradient Boosting Regressor][4]\n",
    "\n",
    "[1]: http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor\n",
    "[2]: http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.ExtraTreesRegressor.html#sklearn.ensemble.ExtraTreesRegressor\n",
    "[3]: http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.AdaBoostRegressor.html#sklearn.ensemble.AdaBoostRegressor\n",
    "[4]: http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingRegressor.html#sklearn.ensemble.GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Optimization\n",
    "\n",
    "After choosing the best model, which currently use defaults, you can usually get some scoring performance gains by tweaking the parameters on the best model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def optimize_random_forest_model(n_iters, n_estimators):\n",
    "    n_iters = int(n_iters)  # I cast as an int only because widgets can only return strings. Likewise on next line.\n",
    "    n_estimators = int(n_estimators)\n",
    "    \n",
    "    cv_iterator = cv.ShuffleSplit(len(X_binarized), n_iter=n_iters, test_size=0.3)\n",
    "    cv_scores = cv.cross_val_score(RandomForestRegressor(n_estimators), \n",
    "                                   X_binarized, \n",
    "                                   Y, \n",
    "                                   cv=cv_iterator, \n",
    "                                   scoring='mean_squared_error')\n",
    "    \n",
    "    return np.mean(-cv_scores), np.std(-cv_scores)\n",
    "\n",
    "\n",
    "    \n",
    "interact(optimize_random_forest_model, \n",
    "         n_estimators=Dropdown(description='Number of Random Forest Estimators', options=['5', '10', '50', '100']),\n",
    "         n_iters=Dropdown(description='Number of Train/Test Iterations', options=['5', '6', '7', '8', '9', '10', '11', '12']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Importance\n",
    "\n",
    "We can query the model to ask what amino acids are most important. To do so, call the `model.feature_importances_` attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rfr = RandomForestRegressor(n_estimators=100)\n",
    "rfr.fit(X_binarized, Y)\n",
    "sorted([i for i in zip(X_binarized.columns, rfr.feature_importances_)], key=lambda x:x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make Predictions\n",
    "\n",
    "The final thing we need to do before moving onto the next class is to make predictions on the rest of the data. \n",
    "\n",
    "Recall the motivation:\n",
    "\n",
    "- For the doctor: having seen the genomic data, he now needs to choose a drug to prescribe that targets the virus. Needs minimal resistance.\n",
    "- For the epidemiologist: she would like to understand the global evolutionary trajectory of HIV, and whether drug resistance is shaping it or not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Load the global sequence data as a `pandas` DataFrame\n",
    "\n",
    "The global HIV protease protein sequence data (`proteases_downsampled.fasta`) is stored in the FASTA file format, in the `sequences/` directory.\n",
    "\n",
    "Note the structure of the `id` field:\n",
    "\n",
    "- HIV subtype\n",
    "- Country code\n",
    "- Year of isolation\n",
    "- Patient ID\n",
    "- Accession Number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "proteases = [s for s in SeqIO.parse('sequences/proteases_downsampled.fasta', 'fasta')]\n",
    "for s in proteases:\n",
    "    if len(s.seq) != 99:\n",
    "        print(s.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "proteases = [s for s in SeqIO.parse('sequences/proteases_downsampled.fasta', 'fasta') if len(s.seq) == 99]\n",
    "proteases = MultipleSeqAlignment(proteases)\n",
    "proteases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Iterate over all of the columns in the multiple sequence alignment, and append it as a \n",
    "proteases_df = pd.DataFrame()\n",
    "\n",
    "for col in range(proteases.get_alignment_length()):\n",
    "    binarized_cols = lb.transform([k for k in proteases[:,col]])\n",
    "    \n",
    "    for i, c in enumerate(lb.classes_):\n",
    "        proteases_df[str(col + 1) + '_' + c] = binarized_cols[:,i]\n",
    "        \n",
    "# Add in the index.\n",
    "index = []\n",
    "for s in proteases:\n",
    "    index.append(s.id)\n",
    "    \n",
    "proteases_df.index = index\n",
    "proteases_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "proteases_df.iloc[0:5, 0:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Model Prediction Outputs\n",
    "\n",
    "Here, I will show you how to output the predictions of the machine learning model to disk as a CSV file.\n",
    "\n",
    "**Live Coding Together**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Fit all four regressor models\n",
    "\n",
    "def fit_model(model, X, Y):\n",
    "    # Instantiate the model\n",
    "    \n",
    "    # Fit the model\n",
    "    \n",
    "    \n",
    "    # Return the model and the model predictions. \n",
    "    return \n",
    "\n",
    "# Train RF, ET, AB and GB models\n",
    "rf_mdl, rf_preds = fit_model(RandomForestRegressor, X_binarized, Y)\n",
    "# Continue below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Zip together the predicted values with the index of the protease dataframe.\n",
    "protease_preds = [i for i in zip(proteases_df.index, rf_mdl.predict(proteases_df))]\n",
    "# Convert it into a dataframe, set the index column to be the IDs, and apply a 10**x transformation\n",
    "protease_preds = pd.DataFrame(protease_preds).set_index(0).apply(lambda x: np.power(10, x))\n",
    "# View the first few lines.\n",
    "protease_preds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Write them to disk.\n",
    "protease_preds.to_csv('csv/FPV_random-forest_preds.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.hist(rf_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
